
FREITAS, Caio Guimarães de [1]

FREITAS, Caio Guimarães de. Ciência de Dados: Big Data e Gestão dos Dados. Revista Científica Multidisciplinar Núcleo do Conhecimento. Ano 05, Ed. 10, Vol. 08, pp. 134-140. Outubro de 2020. ISSN: 2448-0959, Link de acesso: https://www.nucleodoconhecimento.com.br/tecnologia/gestao-dos-dados

Contents [hide]

RESUMO
INTRODUÇÃO
A CIÊNCIA DE DADOS
BIG DATA
GESTÃO DOS DADOS
CONCLUSÃO
REFERÊNCIAS
RESUMO
A ciência de dados lida com a criação de insights ou produtos de dados a partir de um determinado conjunto de arquivos de dados. Os dados manipulados costumam ser conhecidos como “big data” embora sejam frequentemente aplicados a fluxos de dados convencionais, como os normalmente encontrados nos bancos de dados, nas planilhas e nos documentos de texto de uma empresa. O presente artigo tem o objetivo geral de apresentar o aspecto da gestão dos dados na ciência de dados. Analisando os aspectos relevantes relativos à obtenção de dados observados na ciência de dados para obter informações úteis, bem como os cuidados que devem ser tomados quando da obtenção desses dados. Dentre os autores pesquisados para a constituição conceitual deste trabalho, destacaram-se Kampakis (2020), Godsey (2017), Skiena (2017), Corea (2019) e Chen (2018). A metodologia utilizada foi a pesquisa descritiva, tendo como coleta de dados o levantamento bibliográfico. As conclusões mais relevantes são que é fundamental ter em mente que o julgamento humano torna-se essencial para avaliar fatores como adequação dos dados; natureza dos dados; exigência de tempo e custo de aquisição de modo que se este for negligenciado pode trazer prejuízos as organizações tornando inúteis os investimentos feitos aquisições de dados.

Palavras-chave: Ciência de dados, Big data, dados.

INTRODUÇÃO
O interesse das empresas por grandes quantidades de dados tem se intensificado nos últimos anos. Os dados vêm sendo coletados a taxas cada vez maiores e, em muitos casos, são coletados mesmo sem uma finalidade específica. As lojas on-line começaram a armazenar não apenas informações do que é comprado, mas também todos os itens visualizados e todos os links clicados. Sejam públicos ou privados, estruturados ou não estruturados, conjuntos de dados estão se acumulando em todos os lugares.

No passado, os dados eram coletados intencionadamente, de modo que representavam alguma medida intencional do mundo real. Mais recentemente, porém, a Internet, dispositivos eletrônicos onipresentes e um medo latente de perder valor oculto nos dados levaram as organizações a coletar o máximo de dados possível, geralmente com a premissa de que esses dados serão úteis posteriormente. Pela primeira vez na história vários setores estão primeiro coletando os dados e depois se questionando o que pode ser feito com esses dados.

As redes sociais costumam armazenar tudo o que os seus usuários fazem nelas. O objetivo dessa coleta nem sempre é vender os dados embora isso também ocorra. Boa parte dos sites e aplicativos usam seus dados para melhorar a experiência dos usuários. Com isso os proprietários desses sites e aplicativos ficam divididos entre o valor dos dados como algo que pode ser vendido e o valor dos dados quando mantidos e usados ​​internamente.

Muitos editores têm medo de vender seus dados porque isso abre a possibilidade de que outra pessoa descubra algo lucrativo para fazer com eles. Muitos deles mantêm seus dados para si mesmos, guardando-os para o futuro, quando supostamente terão tempo suficiente para extrair todo o valor deles.

O presente artigo tem o objetivo geral de apresentar o aspecto da gestão dos dados na ciência de dados. Delimitando-se a analisar os aspectos relevantes relativos à obtenção de dados observados na ciência de dados para obter informações úteis, bem como os cuidados que devem ser tomados quando da gestão desses dados.

Este trabalho justifica-se pela importância de se conhecer os métodos utilizados pela ciência de dados para obter valor a partir dos dados.

A metodologia deste trabalho é a pesquisa descritiva, tendo como coleta de dados o levantamento bibliográfico.

A CIÊNCIA DE DADOS
A ciência de dados é única no espaço da tecnologia de duas maneiras. Primeiro, em comparação com o desenvolvimento de software, por exemplo, a ciência de dados é intangível. Não se pode ver um front end chamativo, apenas os resultados de um modelo. Em segundo lugar, é a ciência, o que significa que, ao contrário da engenharia, é difícil definir com antecedência um plano perfeitamente definido. A incerteza é parte integrante da ciência de dados, e isso pode dificultar estimativas e decisões. Esses dois fatores tornam o entendimento da ciência de dados mais desafiador (KAMPAKIS, 2020).

Conforme Godsey (2017), as origens da ciência de dados como um campo de estudo estão em algum lugar entre a estatística e o desenvolvimento de software.

A ciência de dados possui três campos principais que incluem, inteligência artificial, aprendizado de máquina e estatística. Deste modo a estatística é uma ferramenta essencial no arsenal de qualquer cientista de dados, porque ajuda a desenvolver e estudar métodos para coletar, analisar, interpretar e apresentar dados. As inúmeras metodologias utilizadas permitem aos cientistas de dados realizações como: projetar experimentos e interpretar resultados para melhorar a tomada de decisão; construir modelos de previsão; transformar dados em insights; fazer estimativas inteligentes etc. (KAMPAKIS, 2020).

De acordo com Skiena (2017), a ciência de dados está na intersecção de ciência da computação, estatística e domínios de aplicação subjacentes. Da ciência da computação vem o aprendizado de máquina e as tecnologias de computação de alto desempenho para lidar com a escala. A partir das estatísticas, vem uma longa tradição de análise exploratória de dados, teste de significância e visualização. Dos domínios de aplicação nos negócios e nas ciências, surgem desafios dignos de batalha e padrões de avaliação para avaliar quando eles foram conquistados adequadamente.

Além das estatísticas e do software, muitas pessoas dizem que a ciência de dados tem um terceiro componente principal, que é algo parecido com a experiência no assunto ou no domínio. Embora seja importante entender um problema antes de tentar resolvê-lo, um bom cientista de dados pode alternar domínios e começar a contribuir um pouco antes (GODSEY, 2017).

Conforme Skiena (2017) existem três razões para essa súbita explosão da ciência de dados:

O avanço tecnológico torna possível capturar e armazenar grandes quantidades dados de mídias sociais, registros e de sensores. Após de reunir todos esses dados, pode-se perguntar o que é possível ser feito com eles.
Os avanços da computação tornam possível analisar os dados de maneiras novas e em escalas cada vez maiores. As arquiteturas de computação em nuvem proporcionam vasto poder até mesmo aos usuários comuns quando necessário. Novas abordagens de aprendizado de máquina têm levado a incríveis avanços em problemas de longa data como visão computacional e processamento de linguagem natural.
Empresas de tecnologia de destaque como Google e Facebook demonstraram o poder da análise de dados moderna. Histórias de sucesso aplicando dados em áreas tão diversas como gestão esportiva e previsão de eleições serviram como modelos para levar a ciência de dados a um grande público.
BIG DATA
Existem várias maneiras de definir o que é big data, e é provavelmente por isso que ainda é um conceito difícil de entender. Alguns autores descrevem big data como um conjunto de dados acima de um certo limite, por exemplo, acima de um terabyte. Trabalhos de maior renome identificaram big data como dados que exibem as características de variedade, velocidade e volume (COREA, 2019).

Para Kampakis (2020), big data é um chavão, pois simplesmente se refere a conjuntos de dados maciços que são tão grandes e complicados que o software tradicional de processamento de dados simplesmente não pode lidar com eles. Além disso, está relacionado a bancos de dados NoSQL, computação em nuvem e assim por diante.

Observa-se, portanto, que big data significa coisas diferentes para pessoas diferentes. Conforme Chen (2018), independente das fontes de dados digitais, como mídia social, bancos de dados, áudio e vídeo, o big data expõe as características de alto volume, alta velocidade de entrada e saída de dados e alta variedade de dados tipos e fontes.

Todos parecem estar corretos de alguma maneira. Já no que diz respeito à análise de big data existe uma definição que parece capturar melhor esse fenômeno: a análise de big data é uma abordagem inovadora que consiste em diferentes tecnologias e processos para extrair informações valiosas de dados de baixo valor que não se encaixam, por qualquer motivo, nos sistemas de banco de dados convencionais (COREA, 2019).

De acordo com Chen (2018), esse novo tipo de dados favorece as perspectivas para o avanço nas pesquisas em vários campos especialmente nas ciências sociais e humanas das seguintes maneiras:

Novas metodologias de pesquisa podem ser estabelecidas com a ajuda de ferramentas avançadas de coleta de big data, como raspagem da Web e técnicas analíticas inovadoras, como aprendizado de máquina;
Novos tipos de dados podem revelar novos padrões e insights sobre a sociedade humana, política e economia;
Novos tipos de dados podem levar a novos tipos de questões de pesquisa que estão além das perspectivas das teorias estabelecidas.
GESTÃO DOS DADOS
O gerenciamento de dados inclui todas as disciplinas envolvidas no trabalho com os dados e o trata como um recurso valioso. Uma definição mais formal é fornecida pelo DAMA International: Gerenciamento de recursos de dados é o desenvolvimento e a execução de arquiteturas, políticas, práticas e procedimentos que gerenciam adequadamente as necessidades do ciclo de vida de dados de uma empresa. (KAMPAKIS, 2020).

Inicialmente, os dados precisam ser contextualizados e seu significado pode mudar dependendo do contexto. Os dados podem ser percebidos como objetivos ou factuais – quando capturam fatos de fenômenos naturais sendo univocamente iguais independentemente de quem os olha – ou subjetivos – se refletem construções puramente humanas ou sociais, que ganham seu direito à representatividade a partir do consenso geral, sendo, portanto, mais abstrato. A interpretação dos dados é a essência de seu valor para os negócios e ambos os tipos de dados podem fornecer insights diferentes para diferentes observadores devido a habilidades de interpretação (COREA, 2019).

Outro ponto a se destacar se refere a qualidade dos dados. Boa parte das vezes, a qualidade dos dados se torna uma questão importante. Outras vezes, a principal questão pode ser o volume de dados, velocidade de processamento, parâmetros de um algoritmo, interpretabilidade dos resultados ou qualquer um dos muitos outros aspectos do problema. Ignorar qualquer um deles no momento em que se torna importante pode comprometer ou invalidar completamente os resultados subsequentes (GODSEY, 2017).

Também não devemos esquecer que uma ampla gama de preconceitos comportamentais pode invalidar a objetividade da análise afeta as pessoas. Os mais comuns entre cientistas e gerentes são: apofenia (padrões distintos onde não há), falácia narrativa (a necessidade de padrões de séries de fatos desconectados), viés de confirmação (a tendência de usar apenas informações que confirmam hipóteses anteriores) – e sua corolário segundo o qual a busca por evidências acabará eventualmente com a descoberta de evidências – e o viés de seleção (a propensão a usar sempre algum tipo de dado, possivelmente os mais conhecidos). (COREA, 2019).

Portanto, para falar em gerenciamento de dados, precisamos entender de onde vêm os dados. Entendendo de onde vêm os dados geramos muitos dados. Praticamente tudo o que se faz gera alguma forma de dados. As empresas, por exemplo, coletam dados de fontes internas, como transações, dados de log e e-mails, mas também de fontes externas, como mídias sociais, fontes de áudio e vídeos (KAMPAKIS, 2020).

No entanto, os dados por si só não fazem sentido, se não forem feitas as perguntas corretas. É aqui que entra o julgamento humano: fazer a pergunta certa e interpretar os resultados ainda são competência do cérebro humano, mesmo que uma questão quantitativa precisa possa ser respondida com mais eficiência por qualquer máquina (COREA, 2019).

Existem dois tipos principais de coleta de dados: observacional e experimental. A coleta de dados observacionais significa que os dados são coletados passivamente, sem a tentativa de controlar as variáveis ​​envolvidas. Por exemplo, coletar feedback do cliente para um livro e um varejista analisando o comportamento do cliente são métodos de coleta observacional, pois não há tentativa de controlar nenhuma variável. A coleta experimental de dados envolve o design e a realização de um experimento, em que determinadas variáveis ​​são controladas enquanto você estuda outras variáveis. Isso é mais comum nos círculos acadêmicos, mas também em contextos clínicos.  Um exemplo perfeito disso é quando uma empresa farmacêutica testa um novo medicamento. Eles montam experimentos onde controlam certas variáveis, como as pessoas envolvidas no estudo, e testam outras variáveis, como a eficácia do medicamento e os possíveis efeitos colaterais (KAMPAKIS, 2020).

O upload de dados pode se revelar uma parte crítica do trabalho de um cientista de dados especialmente quando confrontado com novos desafios. Os dados podem chegar de várias fontes: bancos de dados, arquivos CSV ou Excel, HTML bruto, imagens, gravações de som, APIs fornecendo arquivos JavaScript Object Notation (JSON) e assim por diante (BOSCHETTI, 2018).

Nesse contexto, quando se trata de aquisição de dados, há certas considerações que devem ser feitas. Cada uma delas é essencial e podem chegar ao ponto de afetar todo um modelo de negócios. Estas são: Adequação dos dados; Natureza dos dados; Exigência de tempo; Custo de aquisição (KAMPAKIS, 2020).

Após o upload bem-sucedido dos dados, chega a fase de transferência de dados. Embora estejam disponíveis na memória, inevitavelmente, os dados certamente estarão em uma forma inadequada para qualquer análise e experimentação. Os dados no mundo real são complexos, confusos e, às vezes, errados ou ausentes (BOSCHETTI, 2018).

Deve-se ter em mente, também que mais dados podem implicar custos mais altos e não necessariamente maior precisão. Os custos podem incluir: custos de manutenção mais altos, tanto para armazenamento físico quanto para retenção de modelo; maiores dificuldades em interpretar os resultados; coleta de dados mais onerosa e custos de oportunidade de tempo. Sem dúvida, os dados usados ​​não precisam ser ortodoxos ou usados ​​de maneira padrão e eles podem desafiar a sabedoria convencional, mas precisam ser comprovados e validados. Um conjunto de dados é um requisito básico para qualquer análise estatística e de aprendizado de máquina (BOSCHETTI, 2018).

Por fim, as estratégias de dados inteligentes sempre começam com a análise de conjuntos de dados internos, antes de integrá-los a fontes públicas ou externas. Não é vantajoso armazenar e processar dados apenas por causa dos dados, visto que, com a quantidade de dados gerada diariamente, o ruído aumenta mais rapidamente que o sinal. A regra 80/20 de Pareto se aplica: os 80% do fenômeno provavelmente poderiam ser explicados pelos 20% dos dados de propriedade (COREA, 2019).

CONCLUSÃO
Este estudo tem o objetivo geral de apresentar o aspecto obtenção de dados na ciência de dados. Ao realizar a análise dos aspectos relevantes para a gestão de dados, pode-se observar que existem diversos fatores que podem influenciar a análise para obtenção de insights a partir destes dados.

Ao analisar os fatores que devem ser considerados quando da gestão dos dados em ciência de dados, observa-se também, que mais dados podem implicar custos mais altos e não necessariamente maior precisão dos modelos gerados a partir destes dados. Além disso, muitas variáveis podem vir a aumentar a complexidade de um modelo sem necessariamente aumentar a precisão ou a eficiência deles. Vale lembrar ainda, que a qualidade dos dados é de fundamental importância, visto que dados de baixa qualidade podem invalidar os resultados obtidos.

Portanto é importante ter em mente que fazer a pergunta certa e interpretar os resultados ainda são competência do cérebro humano, de modo que se este for negligenciado, pode trazer prejuízos às organizações tornando inúteis os investimentos feitos em tecnologia para obter insights a partir de grandes quantidades de dados. Além disso pode-se observar que o julgamento humano torna-se essencial para avaliar fatores como adequação dos dados; natureza dos dados; exigência de tempo e custo de aquisição. Os avanços nas técnicas armazenamento e processamento de big data são constantes, de modo que os aspectos considerados importantes podem ser modificados com o tempo. Com isso, novos trabalhos podem ser realizados no sentido de apresentar os avanços e inovações na gestão de dados no contexto da ciência de dados.

REFERÊNCIAS
COREA, Francesco. An Introduction to Data: Everything You Need to Know About AI, Big Data and Data Science. Springer, 2019.

CHEN, Shu-Heng. Big Data in Computational Social Science and Humanities. Springer, 2018.

GODSEY, Brian. Think Like a Data Scientist: Tackle the Data Science Process Step-by-Step, Shelter Island, Manning, 2017.

KAMPAKIS, Stylianos. The Decision Maker’s Handbook for Data Science: a Guide for Non Tecnical Executives, Managers and Founders. London, Apress, 2020.

SKIENA, Steven S. The Data Science Design Manual, Springer, 2017.

[1] Especialização em Redes de Computadores (2015), especialização MBA em Engenharia de Sistemas (2017), graduação em Análise e Desenvolvimento de Sistemas (2013).

Enviado: Abril, 2020.

Aprovado: Outubro, 2020.